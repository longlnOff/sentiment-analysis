{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C - Loading, Saving and Freezing Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Trong notebook này, chúng ta se cùng tìm hiểu các để load custom word embedding trong TorchText, cách để save tất cả các embeddings ta học được trong lúc train và cách để freeze/unfreeze embeddings trong lúc train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Custom Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Để có thể load được, custom embedding phải có cấu trúc như sau: mỗi dòng gồm một từ luôn đúng ở đầu câu, tiếp đến là các giá trị của embedding vector của từ đó, tất cả ngăn cách nhau bởi space. Tất cả các vector phải có cùng kich thước."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dưới đây là một ví dụ về format mà custom embedding cần tuân theo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "great 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "awesome 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "bad -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0\n",
      "terrible -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0\n",
      "awful -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0\n",
      "kwyjibo 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5 0.5 -0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('custom_embeddings/embeddings.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bây giờ, cùng thiết lập các trường nào!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy',\n",
    "                    tokenizer_language='en_core_web_sm')\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load dataset và tạo train, test, valid set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import datasets\n",
    "import random\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lưu ý, ta chỉ có thể load custom embeddings sau khi \"chúng\" được chuyển thành `Vectors` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ta có thể tạo `Vector` object bằng cách truyền vào vị trí của embeddings (`name`), vị trí cho các cached embeddings (`cache`) và một hàm khởi tạo các tokens trong embeddings nhưng không xuất hiện bên trong dataset của chúng ta (`unk_init`). Tương tự các ví dụ trước, ta khởi tạo theo phân phối chuẩn tắc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [00:00<00:00, 402.61it/s]\n"
     ]
    }
   ],
   "source": [
    "import torchtext.vocab as vocab\n",
    "\n",
    "custom_embeddings = vocab.Vectors(name = 'custom_embeddings/embeddings.txt',\n",
    "                                  cache = 'custom_embeddings',\n",
    "                                  unk_init = torch.Tensor.normal_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Để kiểm tra xem word embeddings có được load chính xác hay không, ta có thể hiển thị các words trong custom embeddings đó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': 0,\n",
       " 'great': 1,\n",
       " 'awesome': 2,\n",
       " 'bad': 3,\n",
       " 'terrible': 4,\n",
       " 'awful': 5,\n",
       " 'kwyjibo': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_embeddings.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ta cũng có thể trực tiếp in ra custom embeddings vector đó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "          1.0000,  1.0000,  1.0000,  1.0000],\n",
       "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "          1.0000,  1.0000,  1.0000,  1.0000],\n",
       "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "          1.0000,  1.0000,  1.0000,  1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [ 0.5000, -0.5000,  0.5000, -0.5000,  0.5000, -0.5000,  0.5000, -0.5000,\n",
       "          0.5000, -0.5000,  0.5000, -0.5000,  0.5000, -0.5000,  0.5000, -0.5000,\n",
       "          0.5000, -0.5000,  0.5000, -0.5000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_embeddings.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sau đó, ta sẽ tự xây dựng vocabulary và truyền vào đó `Vectors` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lưu ý là `unk_init` được khai báo khi tạo `Vectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = custom_embeddings)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bây giờ, ta cần kiểm tra xem vector từ điển cho các words trong custom embeddings phải khớp với nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[TEXT.vocab.stoi['good']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[TEXT.vocab.stoi['bad']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Các từ nằm trong custom embeddings nhưng không có trong dataset vocabulary được khởi tạo bởi hàm `unk_init`. Chúng có cùng size với custom embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1117, -0.4966,  0.1631, -0.8817,  0.2891,  0.4899, -0.3853, -0.7120,\n",
       "         0.6369, -0.7141, -1.0831, -0.5547, -1.3248,  0.6970, -0.6631,  1.2158,\n",
       "        -2.5273,  1.4778, -0.1696, -0.9919])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[TEXT.vocab.stoi['kwjibo']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Các phần phía sau tương tự như các notebooks trước."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        text = text.permute(1, 0)\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ta cần đảm bảo `EMBEDDING_DIM` phải giống với embedding dimension trong custom embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 20\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 524,641 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tiếp theo, ta khởi tạo embedding layer để sử dụng các vocabulary vectors mà ta tạo trước đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.4778, -0.1696, -0.9919],\n",
       "        [-0.5675, -0.2772, -2.1834,  ...,  0.8504,  1.0534,  0.3692],\n",
       "        [-0.0552, -0.6125,  0.7500,  ..., -0.1261, -1.6770,  1.2068],\n",
       "        ...,\n",
       "        [ 0.5383, -0.1504,  1.6720,  ..., -0.3857, -1.0168,  0.1849],\n",
       "        [ 2.5640, -0.8564, -0.0219,  ..., -0.3389,  0.2203, -1.6119],\n",
       "        [ 0.1203,  1.5286,  0.6824,  ...,  0.3330, -0.6704,  0.5883]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Khởi tạo các tokens chưa biết và padding tokens embeddings là zero tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "                \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            \n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing and Unfreezing Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Chúng ta sẽ train model trong 10 epochs. Trong 5 epochs đầu, ta đóng bằng các weights của embedding layer. Trong 5 epochs cuối, ta sẽ mở khóa và train cả embedding layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Câu hỏi đưa ra là: tại sao chúng ta phải làm như vậy? \n",
    ">> Câu trả lời là: Đôi khi, pre-trained word embeddings đã rất tốt rồi và không cần phải fine-tuned với model của chúng ta. Nếu đóng bằng embeddings pretrained, ta không cần phải tính gradients cũng như cập nhật weights cho các parameters này, dẫn đến tiết kiệm thời gian cho quá trình training. Một lý do thứ 2 là nếu train cả pre-trained word embeddings, số lượng weights là rất lớn dẫn đến việc khó train model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Để đóng băng embedding weights, ta set `model.ebedding.weight.requires_grad = False`. Câu lệnh này sẽ không tính đạo hàm cho các weights trong embedding layer, dẫn đến các parameters này không được cập nhật khi `optimizer.step()` được gọi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nếu muốn train cả embedding layer, ta làm như sau: `model.ebedding.weight.requires_grad = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\longln3\\Anaconda3\\envs\\python3.7.6\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 59s | Frozen? True\n",
      "\tTrain Loss: 0.727 | Train Acc: 52.50%\n",
      "\t Val. Loss: 0.665 |  Val. Acc: 57.20%\n",
      "Epoch: 02 | Epoch Time: 2m 5s | Frozen? True\n",
      "\tTrain Loss: 0.663 | Train Acc: 60.26%\n",
      "\t Val. Loss: 0.624 |  Val. Acc: 68.90%\n",
      "Epoch: 03 | Epoch Time: 2m 56s | Frozen? True\n",
      "\tTrain Loss: 0.635 | Train Acc: 63.42%\n",
      "\t Val. Loss: 0.589 |  Val. Acc: 69.66%\n",
      "Epoch: 04 | Epoch Time: 2m 14s | Frozen? True\n",
      "\tTrain Loss: 0.608 | Train Acc: 66.04%\n",
      "\t Val. Loss: 0.553 |  Val. Acc: 74.62%\n",
      "Epoch: 05 | Epoch Time: 2m 17s | Frozen? True\n",
      "\tTrain Loss: 0.587 | Train Acc: 68.52%\n",
      "\t Val. Loss: 0.555 |  Val. Acc: 72.26%\n",
      "Epoch: 06 | Epoch Time: 2m 49s | Frozen? False\n",
      "\tTrain Loss: 0.566 | Train Acc: 70.77%\n",
      "\t Val. Loss: 0.498 |  Val. Acc: 77.22%\n",
      "Epoch: 07 | Epoch Time: 2m 44s | Frozen? False\n",
      "\tTrain Loss: 0.520 | Train Acc: 74.30%\n",
      "\t Val. Loss: 0.470 |  Val. Acc: 78.14%\n",
      "Epoch: 08 | Epoch Time: 2m 15s | Frozen? False\n",
      "\tTrain Loss: 0.485 | Train Acc: 76.66%\n",
      "\t Val. Loss: 0.436 |  Val. Acc: 79.86%\n",
      "Epoch: 09 | Epoch Time: 2m 19s | Frozen? False\n",
      "\tTrain Loss: 0.451 | Train Acc: 78.44%\n",
      "\t Val. Loss: 0.408 |  Val. Acc: 81.36%\n",
      "Epoch: 10 | Epoch Time: 2m 23s | Frozen? False\n",
      "\tTrain Loss: 0.417 | Train Acc: 80.82%\n",
      "\t Val. Loss: 0.386 |  Val. Acc: 82.68%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "FREEZE_FOR = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "#freeze embeddings\n",
    "model.embedding.weight.requires_grad = unfrozen = False\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s | Frozen? {not unfrozen}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), './models/tutC-model.pt')\n",
    "    \n",
    "    if (epoch + 1) >= FREEZE_FOR:\n",
    "        #unfreeze embeddings\n",
    "        model.embedding.weight.requires_grad = unfrozen = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./models/tutC-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Đôi khi, ta muốn tái sử dụng các embeddings chúng ta đã train với model khác. Để thực hiện việc này, ta viết một hàm lặp xuyên suốt vocabulary, lấy từ và embedding của từ đó, ghi chúng vào text file sao cho đúng với format đã trình bày ở đầu notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def write_embeddings(path, embeddings, vocab):\n",
    "    \n",
    "    with open(path, 'w') as f:\n",
    "        for i, embedding in enumerate(tqdm(embeddings)):\n",
    "            word = vocab.itos[i]\n",
    "            #skip words with unicode symbols\n",
    "            if len(word) != len(word.encode()):\n",
    "                continue\n",
    "            vector = ' '.join([str(i) for i in embedding.tolist()])\n",
    "            f.write(f'{word} {vector}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ghi embeddings vào file: 'custom_embeddings/trained_embeddings.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25002/25002 [00:00<00:00, 31939.90it/s]\n"
     ]
    }
   ],
   "source": [
    "write_embeddings('custom_embeddings/trained_embeddings.txt', \n",
    "                 model.embedding.weight.data, \n",
    "                 TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kiểm tra embeddings bằng cách load chúng vào vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 24941/24942 [00:00<00:00, 34337.03it/s]\n"
     ]
    }
   ],
   "source": [
    "trained_embeddings = vocab.Vectors(name = 'custom_embeddings/trained_embeddings.txt',\n",
    "                                   cache = 'custom_embeddings',\n",
    "                                   unk_init = torch.Tensor.normal_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cuối cùng, in cả 2 ra để so sánh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1481, -0.2077,  0.2922, -0.1535,  0.0629, -0.0885, -0.2689, -0.2070,\n",
      "         -0.1644,  0.0387,  0.1123, -0.1350,  0.1085, -0.1212, -0.1565, -0.0790,\n",
      "         -0.1630,  0.1002, -0.2173, -0.0834],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.2297, -0.4574,  0.8528, -0.8145, -0.1863,  0.0456, -1.5698, -0.2121,\n",
      "          0.4783,  1.7190, -0.2239, -0.1312, -0.3100, -0.6320,  0.2988,  0.2503,\n",
      "         -0.8606,  0.0651, -1.5308,  1.2659],\n",
      "        [-0.5871, -0.0639,  0.2919, -0.6682, -0.4163, -0.4727, -1.5343,  0.8101,\n",
      "          0.8359,  0.5311, -0.5475, -1.3023, -1.8893,  0.6650, -0.6499, -0.5865,\n",
      "          0.3324, -0.4134,  0.6433,  0.8549],\n",
      "        [-0.6817,  0.2149,  0.5038, -1.6466, -0.0353,  0.2784, -0.1395,  0.5631,\n",
      "         -0.1565,  0.4011,  0.1388, -0.5444,  0.0086, -0.2714, -0.7601, -0.0708,\n",
      "          1.3665,  1.3488,  0.7497, -0.0295]])\n"
     ]
    }
   ],
   "source": [
    "print(trained_embeddings.vectors[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1481, -0.2077,  0.2922, -0.1535,  0.0629, -0.0885, -0.2689, -0.2070,\n",
      "         -0.1644,  0.0387,  0.1123, -0.1350,  0.1085, -0.1212, -0.1565, -0.0790,\n",
      "         -0.1630,  0.1002, -0.2173, -0.0834],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.2297, -0.4574,  0.8528, -0.8145, -0.1863,  0.0456, -1.5698, -0.2121,\n",
      "          0.4783,  1.7190, -0.2239, -0.1312, -0.3100, -0.6320,  0.2988,  0.2503,\n",
      "         -0.8606,  0.0651, -1.5308,  1.2659],\n",
      "        [-0.5871, -0.0639,  0.2919, -0.6682, -0.4163, -0.4727, -1.5343,  0.8101,\n",
      "          0.8359,  0.5311, -0.5475, -1.3023, -1.8893,  0.6650, -0.6499, -0.5865,\n",
      "          0.3324, -0.4134,  0.6433,  0.8549],\n",
      "        [-0.6817,  0.2149,  0.5038, -1.6466, -0.0353,  0.2784, -0.1395,  0.5631,\n",
      "         -0.1565,  0.4011,  0.1388, -0.5444,  0.0086, -0.2714, -0.7601, -0.0708,\n",
      "          1.3665,  1.3488,  0.7497, -0.0295]])\n"
     ]
    }
   ],
   "source": [
    "print(model.embedding.weight.data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('python3.7.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94b83b56f38ffef65d6a4ee563210b313d606c3429660e46922f3bd794e4159a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
