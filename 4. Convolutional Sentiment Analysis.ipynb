{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Convolutional Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ở notebooks trước, chúng ta đã đạt được accuracy xấp xỉ 85% bằng cách sử dụng RNNs và áp dụng mô hình trong paper [Bag of Tricks for Efficient Text Classification](https://arxiv.org/pdf/1607.01759.pdf). Trong notebook này, chúng ta sẽ cùng nhau tìm hiểu và áp dụng *convolutional neural network (CNN) để xây dựng một mô hình phân tích cảm xúc, áp dụng mô hình trong bài báo [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1408.5882.pdf)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LƯU Ý: Notebook này chỉ tóm gọn về convolutional neural network. Để biết thêm chi tiết về CNNs, bạn có thể tham khảo [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/convolutional-networks/). và [Convolutional Neural Networks Coursera](https://www.coursera.org/learn/convolutional-neural-networks), hoặc [Convolutional Neural Networks blog](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Thông thường, CNNs được sử dụng trong phân tích ảnh. CNNs thường được tạo bởi một hoặc nhiều lớp tích chập - *convolutional* layers, theo sau là một hoặc nhiều *linear layers*. *Convolutional* layers sử dụng các *filters* (còn được gọi là *kernels* hoặc *receptive fields*) quét ngang qua một bức ảnh và sinh ra một bức ảnh mới đã được xử lý. Bức ảnh mới này có thể đưa qua các lớp covolutional hoặc linear tùy bài toán. Mỗi filter đều có kích thước, ví dụ một filter 3x3 có chiều dài là 3, rộng 3 và tổng cộng có 9 trọng số. Trong xử lý ảnh truyền thống, các trọng số này sẽ được tính toán bằng tay. Tuy nhiên, với CNNs, các trọng số này được học thông qua *backpropagation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ý tưởng của việc học các trọng số là mỗi *convolutional* layer hoạt động như một bộ trích xuất đặc trưng - *feature extractors*, trích xuất những phần quan trọng trong bức ảnh. Ví dụ, nếu sử dụng CNN để phát hiện khuôn mặt, CNN sẽ nhìn vào những đặc trưng quan trọng của khuôn mặt như: mắt, mũi, miệng, lông mày, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Thế, tại sao lại sử dụng CNNs cho văn bản? Tương tự như việc xử lý ảnh với filter 3x3, một filter 1x2 có thể nhanh chóng kiểm tra 2 từ liền nhau trong một đoạn văn bản, ví dụ: bi-gram. Ở Notebook trước, chúng ta sử dụng FastText model - sử dụng bi-grams bằng cách chèn chúng vào cuối mỗi câu. Lần này, chúng ta sẽ sử dụng CNNs để học bi-grams (1x2 filter) một cách tự động, bên cạnh đó còn học tri-grams (1x3 filter), ..., n-grams (1xn filter) trong văn bản. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Trực giác cho thấy rằng: nếu có một số bi-grams, tri-grams và n-grams nhất định xuất hiện trong bài đánh giá, đó sẽ là dấu hiệu tốt để đưa ra kết luận cuối cùng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ta xây dựng tập dữ liệu tương tự notebook 2. <br>\n",
    "> Do convolutional layers yêu cầu số chiều của batch phải nằm trước nên ta sử dụng `batch_first=True` khi khởi tạo `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy',\n",
    "                    tokenizer_language='en_core_web_sm',\n",
    "                    batch_first = True)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Xây dựng vocab và load pre-trained word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data,\n",
    "                    max_size = MAX_VOCAB_SIZE,\n",
    "                    vectors = \"glove.6B.100d\",\n",
    "                    unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tương tự như các notebook trước, ta tạo iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = \\\n",
    "    data.BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data),\n",
    "        batch_size = BATCH_SIZE,\n",
    "        device = device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "169dd4cfa2618b85e8ef5e64ff9d70433b2e7f87b8c66bdf4b101e8e57acbaaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
